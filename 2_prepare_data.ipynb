{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Process the raw data from pyapm and bpnsdata\n",
    "This notebook is the code to process the output given after processing the data with pypam and bpnsdata\n",
    "For more information about this process please contact clea.parcerisas@vliz.be or check the documentation of both packages\n",
    "https://lifewatch-pypam.readthedocs.io/en/latest/\n",
    "https://github.com/lifewatch/bpnsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\cleap\\envs\\sound-data-utils\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cleap\\envs\\sound-data-utils\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages. Geopandas can give problems in Windows machines, so better to install them using wheels when using Windows\n",
    "import sys\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the chunk times to analyze (in seconds)\n",
    "CHUNK_LENGTH = 5\n",
    "TIME_CHUNK_LENGTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List of the deployments that should be skipped after doing a quality check\n",
    "DEPLOYMENTS_TO_SKIP_ETN = [9815, 9816, 9819, 9826, 9808, 9821, 9849, 9853, 9854, 13241, 13244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ENV_LABELS = [\n",
    "    'shipping',\n",
    "    'season',\n",
    "    'moon_phase',\n",
    "    'day_moment',\n",
    "    'benthic_habitat',\n",
    "    'substrate',\n",
    "    'seabed_habitat',\n",
    "    'tide',\n",
    "    'salinity',\n",
    "    'temperature',\n",
    "    'current',\n",
    "    'bathymetry',\n",
    "    'shipwreck_distance',\n",
    "    'coast_dist'\n",
    "]\n",
    "\n",
    "SAMPLE_LABELS = [\n",
    "    'instrument_name',\n",
    "    'instrument_depth',\n",
    "    'etn_id',\n",
    "    'campaign'\n",
    "]\n",
    "\n",
    "ARTIFACTS_LABELS = ['datetime',\n",
    "                    'filename',\n",
    "                    'grouped_start_sample',\n",
    "                    'grouped_end_sample',\n",
    "                    'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_VARS = ['day_moment', 'benthic_habitat', 'substrate', 'seabed_habitat', 'instrument_name', 'etn_id',\n",
    "                    'campaign', 'label']\n",
    "CYCLIC_VARS = ['season', 'moon_phase']\n",
    "\n",
    "vars_dtypes = {\n",
    "    'shipping': int,\n",
    "    'season': int,\n",
    "    'moon_phase': np.float16,\n",
    "    'day_moment': 'category',\n",
    "    'benthic_habitat': 'category',\n",
    "    'substrate': 'category',\n",
    "    'seabed_habitat': 'category',\n",
    "    'tide': np.float16,\n",
    "    'salinity': np.float16,\n",
    "    'temperature': np.float16,\n",
    "    'current': np.float16,\n",
    "    'bathymetry': np.float16,\n",
    "    'shipwreck_distance': np.float16,\n",
    "    'coast_dist': int,\n",
    "    'instrument_depth': np.float16\n",
    "}\n",
    "\n",
    "# New names for environmental variables for easier use\n",
    "env_labels_rename = {\n",
    "    'sea_surface_height_above_sea_level': 'tide',\n",
    "    'sea_surface_salinity': 'salinity',\n",
    "    'sea_surface_temperature': 'temperature',\n",
    "    'surface_baroclinic_sea_water_velocity': 'current',\n",
    "    'route_density': 'shipping'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the folders\n",
    "data_path = pathlib.Path('./data/raw_data/')\n",
    "processed_data_path = pathlib.Path('./data/processed/')\n",
    "raw_data_path = pathlib.Path('./data/raw_data/deployments/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the metadata csv\n",
    "metadata = pd.read_csv(data_path.joinpath('data_summary_mda.csv'))\n",
    "metadata = metadata.loc[~metadata.etn_id.isin(DEPLOYMENTS_TO_SKIP_ETN)]\n",
    "\n",
    "# Read the labelled data\n",
    "labels_bad_data = pd.read_csv(data_path.joinpath('labels.csv'), parse_dates=['start_datetime',\n",
    "                                                                                 'end_datetime',\n",
    "                                                                                 'start_file'])\n",
    "\n",
    "# Decide to join the bins 5 in 5\n",
    "n_join_bins = 5\n",
    "\n",
    "# Create the empty output vars\n",
    "df_features = pd.DataFrame()\n",
    "df_sample = pd.DataFrame()\n",
    "df_env = pd.DataFrame()\n",
    "df_geo = geopandas.GeoDataFrame()\n",
    "df_labels = pd.DataFrame()\n",
    "\n",
    "# Define the names of the vars that will be used\n",
    "features_var = 'oct3'\n",
    "freqticks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:08<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of time recorded 40.7910209025 h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Join all the deployments in one DataFrame\n",
    "df = pd.DataFrame()\n",
    "total_acoustic_time = 0\n",
    "for idx in tqdm(metadata.index, total=len(metadata)):\n",
    "    deployment_row = metadata.loc[idx]\n",
    "    env_name = '%s_%s_env.nc' % (idx, deployment_row.deployment_name)\n",
    "    env_path = processed_data_path.joinpath(env_name)\n",
    "    deployment_file_name = '%s_%s.nc' % (idx, deployment_row.deployment_name)\n",
    "    name = deployment_row['deployment_name']\n",
    "    deployment = xarray.open_dataset(env_path)\n",
    "\n",
    "    deployment = deployment.rename(env_labels_rename)\n",
    "\n",
    "    # Eliminate the frequencies below 60 Hz and above 45 kHz\n",
    "    deployment = deployment.sel(frequency=deployment.frequency[deployment.frequency < 45000])\n",
    "    deployment = deployment.sel(frequency=deployment.frequency[deployment.frequency > 60])\n",
    "    deployment_duration = deployment.datetime.max() - deployment.datetime.min()\n",
    "    total_acoustic_time += deployment_duration\n",
    "    deployment = deployment[ENV_LABELS + [features_var]].dropna('grouped_id', 'any')\n",
    "    clean_freqticks = deployment.frequency.values\n",
    "\n",
    "    if len(deployment.id) > 0:\n",
    "        values_arr = deployment[features_var].values\n",
    "        if len(deployment.dims) > 2:\n",
    "            values_arr = values_arr.reshape((deployment.dims['grouped_id'],\n",
    "                                             deployment.dims['time_window'] *\n",
    "                                             deployment.dims['frequency']), order='F')\n",
    "\n",
    "            df_deployment = pd.DataFrame(values_arr)\n",
    "            df_deployment = df_deployment.astype(np.float16)\n",
    "            for env in ENV_LABELS:\n",
    "                df_deployment[env] = deployment[env].values\n",
    "\n",
    "            for sam in SAMPLE_LABELS:\n",
    "                df_deployment[sam] = deployment_row.loc[sam]\n",
    "\n",
    "            # Add the geometry\n",
    "            geo_series = geopandas.GeoSeries(data=geopandas.points_from_xy(x=deployment['lon'],\n",
    "                                                                           y=deployment['lat']),\n",
    "                                             crs='EPSG:4326')\n",
    "\n",
    "            df_deployment = geopandas.GeoDataFrame(df_deployment, geometry=geo_series)\n",
    "\n",
    "            # Add the corresponding label by reading the csv with labels\n",
    "            df_deployment['datetime'] = deployment.grouped_datetime\n",
    "            df_deployment['filename'] = deployment.sel(time_window=0).file_path.values\n",
    "            df_deployment['grouped_start_sample'] = deployment.grouped_start_sample.values\n",
    "            df_deployment['grouped_end_sample'] = deployment.grouped_end_sample.values\n",
    "            df_deployment['label'] = 'unknown'\n",
    "            for _, label_row in labels_bad_data.iterrows():\n",
    "                if deployment_file_name == label_row.filepath:\n",
    "                    mask_label = (df_deployment.datetime < (label_row.end_datetime -\n",
    "                                                            datetime.timedelta(seconds=CHUNK_LENGTH))) & \\\n",
    "                                 (df_deployment.datetime > label_row.start_datetime)\n",
    "                    if len(mask_label) > 0:\n",
    "                        df_deployment.loc[mask_label, 'label'] = label_row.label\n",
    "\n",
    "            df = pd.concat([df, df_deployment], ignore_index=True)\n",
    "\n",
    "# print the total acoustic time\n",
    "print('Total amount of time recorded %s h' % (total_acoustic_time.values / np.timedelta64(1, 'h')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Some data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Change the data types to save some computational power and memory\n",
    "# Some operations\n",
    "df = df.replace(['Civil twilight', 'Astronomical twilight', 'Nautical twilight'], ['Twilight', 'Twilight', 'Twilight'])\n",
    "df['shipwreck_distance'] = np.log(df['shipwreck_distance'])\n",
    "df['bathymetry'] = -1 * df['bathymetry']\n",
    "df['distance_to_bottom'] = df['bathymetry'] - df['instrument_depth']\n",
    "\n",
    "# Categorical vars to category for efficient storage and processing\n",
    "for env, env_type in vars_dtypes.items():\n",
    "    df[env] = df[env].astype(env_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save the outputs to work on with the next script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the deployments to skip if there were any\n",
    "bad_deployments = df.etn_id.astype(int).isin(DEPLOYMENTS_TO_SKIP_ETN)\n",
    "df_good_deployments = df.loc[~bad_deployments]\n",
    "np.save(processed_data_path.joinpath('used_freqticks.npy'), clean_freqticks)\n",
    "df_good_deployments.to_pickle(processed_data_path.joinpath('df_complete.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}