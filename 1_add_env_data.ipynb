{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Add environmental data\n",
    "This notebook is the code to add environmental data to the output of pypam\n",
    "For more information about this process please contact clea.parcerisas@vliz.be or check the documentation of both packages\n",
    "https://lifewatch-pypam.readthedocs.io/en/latest/\n",
    "https://github.com/lifewatch/bpnsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install the required packages. Geopandas can give problems in Windows machines, so better to install them using wheels when using Windows\n",
    "import sys\n",
    "!{sys.executable} -m pip install shapely==1.8.2\n",
    "!{sys.executable} -m pip install bpnsdata\n",
    "!{sys.executable} -m pip install pygeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "from tqdm import tqdm\n",
    "\n",
    "import bpnsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_path = pathlib.Path('./data/raw_data')\n",
    "processed_data_path = pathlib.Path('./data/processed')\n",
    "metadata_path = raw_data_path.joinpath('data_summary_mda.csv')\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "if not processed_data_path.exists():\n",
    "    os.mkdir(processed_data_path)\n",
    "\n",
    "# survey_params\n",
    "binsize = 1.0\n",
    "n_join_bins = 5\n",
    "join_bins_overlap = 0.6\n",
    "\n",
    "env_vars = [\n",
    "\t\t\"shipping\",\n",
    "\t\t\"time\",\n",
    "\t\t\"habitat_suitability\",\n",
    "\t\t\"seabed_habitat\",\n",
    "\t\t\"sea_surface\",\n",
    "\t\t\"sea_wave\",\n",
    "\t\t\"wrakken_bank\",\n",
    "\t\t\"bathymetry\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def group_ds(ds, binsize, n_join_bins=None, join_bins_overlap=None):\n",
    "    if n_join_bins not in [1, None]:\n",
    "        n_overlap = (1 - join_bins_overlap) * n_join_bins\n",
    "        if not n_overlap.is_integer():\n",
    "            print('Warning, the overlap percentage of bins is not an integer. It will be set to the closer integer')\n",
    "        n_overlap = int(n_overlap)\n",
    "        time_window = list((np.arange(0, n_join_bins)) * binsize)\n",
    "        grouped_id = 0\n",
    "        new_ds = xarray.Dataset()\n",
    "\n",
    "        for filename, file_ds in ds.groupby('file_path'):\n",
    "            start_groups_id = np.arange(file_ds.id.min(), file_ds.id.max(), n_overlap)\n",
    "            print('Grouping file %s' % filename)\n",
    "            for start_id_small_window in tqdm(start_groups_id, total=len(start_groups_id - 1), position=0, leave=True):\n",
    "                # Only add the windows that are complete!\n",
    "                if start_id_small_window + n_join_bins < file_ds.id.max():\n",
    "                    selected_ids = np.arange(start_id_small_window, start_id_small_window + n_join_bins)\n",
    "                    small_window = file_ds.sel(id=selected_ids)\n",
    "                    small_window = small_window.expand_dims('grouped_id')\n",
    "                    small_window = small_window.assign_coords({'time_window': ('id', time_window[:len(selected_ids)]),\n",
    "                                                               'grouped_id': [grouped_id]})\n",
    "                    small_window = small_window.swap_dims({'id': 'time_window'})\n",
    "\n",
    "                    if grouped_id == 0:\n",
    "                        new_ds = small_window\n",
    "                    else:\n",
    "                        new_ds = xarray.concat((new_ds, small_window), 'grouped_id')\n",
    "                    grouped_id += 1\n",
    "        new_ds = new_ds.assign_coords({'grouped_datetime': ('grouped_id', new_ds.sel(time_window=0.0).datetime.values),\n",
    "                                       'grouped_start_sample': ('grouped_id',\n",
    "                                                                new_ds.sel(time_window=0.0).start_sample.values),\n",
    "                                       'grouped_end_sample': ('grouped_id',\n",
    "                                                              new_ds.sel(time_window=time_window[-1]).end_sample.values)\n",
    "                                       })\n",
    "        ds = new_ds\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/0_Heinkel 111_env.nc\n",
      "data/processed/1_HMS Colsay_env.nc\n",
      "data/processed/2_Lola_env.nc\n",
      "data/processed/3_Buitenratel_env.nc\n",
      "data/processed/4_Killmore_env.nc\n",
      "data/processed/5_Westhinder_env.nc\n",
      "data/processed/6_Reefballs Belwind_env.nc\n",
      "data/processed/7_Reefballs CPower_env.nc\n",
      "data/processed/8_Gardencity_env.nc\n",
      "data/processed/9_Gardencity_env.nc\n",
      "data/processed/10_G88_env.nc\n",
      "data/processed/11_Loreley_env.nc\n",
      "data/processed/12_Loreley_env.nc\n",
      "data/processed/13_Loreley_env.nc\n",
      "data/processed/14_Nautica Ena_env.nc\n",
      "data/processed/15_Senator_env.nc\n",
      "data/processed/16_Birkenfels_env.nc\n",
      "data/processed/17_Buitenratel_env.nc\n",
      "data/processed/18_Gardencity_env.nc\n",
      "Grouping file \\\\qarchive\\data_sensors\\b&k\\COVID-19\\20200601_SailingTrip\\Gardencity\\200602192000_860_mono1_1mV_Pa.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 130.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping file \\\\qarchive\\data_sensors\\b&k\\COVID-19\\20200601_SailingTrip\\Gardencity\\200602192200_861_mono1_1mV_Pa.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1811/1811 [00:19<00:00, 95.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gardencity 1819 1819\n",
      "Adding shipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee7b826d5224135b3e52d60c9c93e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 18/67 [00:32<01:28,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding habitat_suitability...\n",
      "Adding seabed_habitat...\n",
      "Adding sea_surface...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -51] NetCDF: Unknown file format: b'/tmp/erddapy_g95fhszt.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/erddapy/netcdf_handling.py:18\u001b[0m, in \u001b[0;36m_nc_dataset\u001b[0;34m(url, auth, **requests_kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# if libnetcdf is not compiled with in-memory support fallback to a local tmp file\u001b[39;00m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: b'BCZ_HydroState_V1.nc'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m geodf \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39madd_geodata(df, gps_path, time_tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m geodf \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39msurvey_location\u001b[38;5;241m.\u001b[39madd_distance_to_coast(geodf, coastfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./geo/belgium_coast/basislijn_BE.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m geodf_env \u001b[38;5;241m=\u001b[39m \u001b[43mmanager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeodf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Remove the UTC (xarray does not support it?)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m geodf_env\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m geodf_env\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/bpnsdata/sea_data_manager.py:52\u001b[0m, in \u001b[0;36mSeaDataManager.__call__\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         df \u001b[38;5;241m=\u001b[39m env_class(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[env_name])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43menv_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/bpnsdata/griddap.py:165\u001b[0m, in \u001b[0;36mSeaSurfaceData.__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_baroclinic_sea_water_velocity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_baroclinic_eastward_sea_water_velocity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    167\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_baroclinic_northward_sea_water_velocity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                                                                ]] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/bpnsdata/griddap.py:62\u001b[0m, in \u001b[0;36mRBINSerddap.__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/bpnsdata/griddap.py:119\u001b[0m, in \u001b[0;36mRBINSerddap.get_data\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    117\u001b[0m not_empty_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(df\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mis_empty \u001b[38;5;241m|\u001b[39m df\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39misna())\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     griddap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Is there a xarray function?\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     lat_points \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(df\u001b[38;5;241m.\u001b[39mloc[not_empty_values]\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39my, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/erddapy/erddapy.py:614\u001b[0m, in \u001b[0;36mERDDAP.to_xarray\u001b[0;34m(self, **kw)\u001b[0m\n\u001b[1;32m    612\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgriddap\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mncCF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_download_url(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 614\u001b[0m nc \u001b[38;5;241m=\u001b[39m \u001b[43m_nc_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mopen_dataset(xr\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mNetCDF4DataStore(nc), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/conda/envs/py39/lib/python3.9/site-packages/erddapy/netcdf_handling.py:22\u001b[0m, in \u001b[0;36m_nc_dataset\u001b[0;34m(url, auth, **requests_kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# if libnetcdf is not compiled with in-memory support fallback to a local tmp file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _tempnc(data) \u001b[38;5;28;01mas\u001b[39;00m _nc:\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_nc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -51] NetCDF: Unknown file format: b'/tmp/erddapy_g95fhszt.nc'"
     ]
    }
   ],
   "source": [
    "# Define the seadatamanager\n",
    "manager = bpnsdata.SeaDataManager(env_vars)\n",
    "id_name = 'grouped_id'\n",
    "datetime_name = 'grouped_datetime'\n",
    "for i, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    deployment_path = raw_data_path.joinpath('deployments', row['deployment_path'])\n",
    "    env_path = processed_data_path.joinpath(row['deployment_path'].replace('.nc', '_env.nc'))\n",
    "    print(env_path)\n",
    "    if not env_path.exists():\n",
    "        gps_path = raw_data_path.joinpath('gps', row['gps_path'])\n",
    "\n",
    "        # Read the dataset\n",
    "        ds_deployment = xarray.open_dataset(deployment_path)\n",
    "        ds_deployment = group_ds(ds_deployment, binsize=binsize,\n",
    "                                 n_join_bins=n_join_bins, join_bins_overlap=join_bins_overlap)\n",
    "        # Get the time information from the dataset to get a pandas df\n",
    "        datetime_index = ds_deployment[datetime_name].to_index()\n",
    "        df = pd.DataFrame({\"datetime\": datetime_index.values, 'id': ds_deployment[id_name]})\n",
    "        df = df.drop_duplicates(\"datetime\")\n",
    "        print(metadata.iloc[i]['deployment_name'], len(datetime_index), len(df))\n",
    "        df = df.set_index('datetime')\n",
    "        df.index = df.index.tz_localize('UTC')\n",
    "\n",
    "        # Generate the location information\n",
    "        geodf = manager.add_geodata(df, gps_path, time_tolerance='5s')\n",
    "        geodf = manager.survey_location.add_distance_to_coast(geodf, coastfile='./geo/belgium_coast/basislijn_BE.shp')\n",
    "        geodf_env = manager(geodf)\n",
    "\n",
    "        # Remove the UTC (xarray does not support it?)\n",
    "        geodf_env.index = geodf_env.index.tz_localize(None)\n",
    "        lat = geodf_env['geometry'].y\n",
    "        lon = geodf_env['geometry'].x\n",
    "        df_env = geodf_env.drop(columns=['geometry', 'id'])\n",
    "        env_ds = df_env.to_xarray()\n",
    "        env_ds = env_ds.assign_coords(coords={'lat': lat, 'lon': lon, id_name : ('datetime', df.id.values)})\n",
    "        env_ds = env_ds.swap_dims({'datetime': id_name})\n",
    "\n",
    "        # Clean the previous if not all computed\n",
    "        if len(env_ds[id_name]) != len(ds_deployment[id_name]):\n",
    "            env_ds = env_ds.reindex_like(ds_deployment)\n",
    "        new_ds = ds_deployment.merge(env_ds, compat=\"override\")\n",
    "        new_ds['season'] = new_ds[datetime_name].dt.isocalendar().week\n",
    "\n",
    "        encoding = {'file_path': {'dtype': 'unicode'},\n",
    "                    'start_sample': {'dtype': int, '_FillValue': -1},\n",
    "                    'end_sample': {'dtype': int, '_FillValue': -1},\n",
    "                    'datetime': {'dtype': float, '_FillValue': -1}}\n",
    "        new_ds.to_netcdf(env_path,  encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
